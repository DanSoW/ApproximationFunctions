{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d7063a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import sys\n",
    "sys.maxsize\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "721459cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "## parameter class fis parameters\n",
    "class fis_parameters():\n",
    "    def __init__(self,n_input=3, n_memb=3, batch_size=16, n_epochs=25, memb_func='gaussian',optimizer='sgd', loss='mse'):\n",
    "        self.n_input = n_input  # no. of Regressors\n",
    "        self.n_memb = n_memb  # no. of fuzzy memberships\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.memb_func = memb_func  # 'gaussian' / 'gbellmf'\n",
    "        self.optimizer = optimizer   # sgd / adam /\n",
    "        self.loss = loss     ## mse / mae\n",
    "\n",
    "\n",
    "# Main Class ANFIS\n",
    "class ANFIS:\n",
    "    def __init__(self, n_input, n_memb, batch_size=16, memb_func = 'gaussian', name = 'MyAnfis'):\n",
    "        self.n = n_input\n",
    "        self.m = n_memb\n",
    "        self.batch_size = batch_size\n",
    "        self.memb_func = memb_func\n",
    "        input_ = keras.layers.Input(shape=(n_input), name='inputLayer', batch_size = batch_size)\n",
    "        L1 = FuzzyLayer(n_input, n_memb, memb_func, name='fuzzyLayer')(input_)\n",
    "        L2 = RuleLayer(n_input, n_memb, name='ruleLayer')(L1)\n",
    "        L3 = NormLayer(name='normLayer')(L2)\n",
    "        L4 = DefuzzLayer(n_input, n_memb, name='defuzzLayer')(L3, input_)\n",
    "        L5 = SummationLayer(name='sumLayer')(L4)\n",
    "        self.model = keras.Model(inputs=[input_], outputs=[L5], name = name)\n",
    "        self.update_weights()\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.model.predict(X, batch_size=16)\n",
    "\n",
    "    def update_weights(self):\n",
    "        # premise parameters (mu&sigma for gaussian // a/b/c for bell-shaped)\n",
    "        if self.memb_func == 'gaussian':\n",
    "            self.mus , self.sigmas = self.model.get_layer('fuzzyLayer').get_weights()\n",
    "        elif self.memb_func == 'gbellmf':\n",
    "            self.a , self.b, self.c = self.model.get_layer('fuzzyLayer').get_weights()\n",
    "        # consequence parameters\n",
    "        self.bias, self.weights = self.model.get_layer('defuzzLayer').get_weights()\n",
    "\n",
    "    def plotmfs(self, show_initial_weights=False):\n",
    "        n_input = self.n\n",
    "        n_memb = self.m\n",
    "\n",
    "        if self.memb_func == 'gaussian':\n",
    "            mus, sigmas = np.around(self.model.get_layer('fuzzyLayer').get_weights(),2)\n",
    "            mus, sigmas = mus.reshape((n_memb, n_input, 1)), sigmas.reshape(n_memb , n_input, 1)\n",
    "\n",
    "            xn = np.linspace(np.min(mus)-2*np.max(abs(sigmas)),np.max(mus)+2*np.max(abs(sigmas)), 100).reshape((1,1,-1))\n",
    "            xn = np.tile(xn, (n_memb, n_input, 1))\n",
    "\n",
    "            # broadcast all curves in one array\n",
    "            memb_curves = np.exp(-np.square((xn-mus))/np.square(sigmas))\n",
    "\n",
    "            if show_initial_weights:\n",
    "                mus_init, sigmas_init = np.around(self.init_weights,2)\n",
    "                mus_init, sigmas_init = mus_init.reshape(n_memb, n_input, 1), sigmas_init.reshape(n_memb, n_input, 1)\n",
    "                init_curves = np.exp(-np.square((xn-mus_init))/np.square(sigmas_init))\n",
    "\n",
    "        elif self.memb_func == 'gbellmf':\n",
    "            a, b, c = np.around(self.model.get_layer('fuzzyLayer').get_weights(),2)\n",
    "            a, b, c = a.reshape((n_memb, n_input, 1)), b.reshape(n_memb, n_input, 1), c.reshape(n_memb, n_input, 1)\n",
    "\n",
    "            xn = np.linspace(np.min(c)-2*np.max(abs(a)),np.max(c)+2*np.max(abs(a)), 100).reshape((1,1,-1))\n",
    "            xn = np.tile(xn, (n_memb, n_input, 1))\n",
    "\n",
    "            # broadcast all curves in one array\n",
    "            memb_curves= 1/(1+np.square((xn-c)/a)**b)\n",
    "\n",
    "            if show_initial_weights:\n",
    "                a_init, b_init, c_init = np.around(self.init_weights,2)\n",
    "                a_init, b_init, c_init = a_init.reshape((n_memb, n_input, 1)), b_init.reshape(n_memb, n_input, 1), c_init.reshape(n_memb, n_input, 1)\n",
    "                init_curves = 1/(1+np.square((xn-c_init)/a_init)**b_init)\n",
    "\n",
    "        elif self.memb_func == 'sigmoid':\n",
    "            gammas, c = np.around(self.model.get_layer('fuzzyLayer').get_weights(),2)\n",
    "            gammas, c = gammas.reshape((n_memb, n_input, 1)), c.reshape(n_memb , n_input, 1)\n",
    "\n",
    "            xn = np.linspace(np.min(c)-2*np.max(abs(c)),np.max(c)+2*np.max(abs(c)), 100).reshape((1,1,-1))  #TODO: change confidence bands\n",
    "            xn = np.tile(xn, (n_memb, n_input, 1))\n",
    "\n",
    "            # broadcast all curves in one array\n",
    "            memb_curves = 1 / (1 + np.exp(-gammas*(xn-c)))\n",
    "\n",
    "            if show_initial_weights:\n",
    "                gammas_init, c_init = np.around(self.init_weights,2)\n",
    "                gammas_init, c_init = gammas_init.reshape(n_memb, n_input, 1), c_init.reshape(n_memb, n_input, 1)\n",
    "                init_curves = 1 / (1 + np.exp(-gammas_init*(xn-c_init)))\n",
    "\n",
    "        fig, axs = plt.subplots(nrows=n_input, ncols=1, figsize=(8, self.n*3))\n",
    "        fig.suptitle('Membership functions', size=16)\n",
    "        for n in range(self.n):\n",
    "            axs[n].grid(True)\n",
    "            axs[n].set_title(f'Input {n+1}')\n",
    "            for m in range(self.m):\n",
    "                axs[n].plot(xn[m,n,:], memb_curves[m,n,:])\n",
    "\n",
    "        if show_initial_weights: # plot initial membership curve\n",
    "            for n in range(self.n):\n",
    "                axs[n].set_prop_cycle(None) # reset color cycle\n",
    "                for m in range(self.m):\n",
    "                    axs[n].plot(xn[m,n,:], init_curves[m,n,:], '--', alpha=.5)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        # save initial weights in the anfis class\n",
    "        self.init_weights = self.model.get_layer('fuzzyLayer').get_weights()\n",
    "\n",
    "        # fit model & update weights in the anfis class\n",
    "        history = self.model.fit(X,y, **kwargs)\n",
    "        self.update_weights()\n",
    "\n",
    "        # clear the graphs\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        return history\n",
    "\n",
    "    def get_memberships(self, Xs):\n",
    "        intermediate_layer_model = keras.Model(inputs = self.model.input,\n",
    "                                               outputs = self.model.get_layer('normLayer').output)\n",
    "        intermediate_output = intermediate_layer_model.predict(Xs)\n",
    "\n",
    "        return intermediate_output\n",
    "\n",
    "\n",
    "\n",
    "# Custom weight initializer\n",
    "def equally_spaced_initializer(shape, minval=-1.5, maxval=1.5, dtype=tf.float32):\n",
    "    \"\"\"\n",
    "    Custom weight initializer:\n",
    "        euqlly spaced weights along an operating range of [minval, maxval].\n",
    "    \"\"\"\n",
    "    linspace = tf.reshape(tf.linspace(minval, maxval, shape[0]),\n",
    "                          (-1,1))\n",
    "    return tf.Variable(tf.tile(linspace, (1,shape[1])))\n",
    "\n",
    "\n",
    "\n",
    "# Layer 1\n",
    "class FuzzyLayer(keras.layers.Layer):\n",
    "    def __init__(self, n_input, n_memb, memb_func='gaussian', **kwargs):\n",
    "        super(FuzzyLayer, self).__init__(**kwargs)\n",
    "        self.n = n_input\n",
    "        self.m = n_memb\n",
    "        self.memb_func = memb_func\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.batch_size = batch_input_shape[0]\n",
    "\n",
    "        if self.memb_func == 'gbellmf':\n",
    "            self.a = self.add_weight(name='a',\n",
    "                            shape=(self.m, self.n),\n",
    "                            initializer = keras.initializers.RandomUniform(minval=.7, maxval=1.3, seed=1),\n",
    "                            #initializer = 'ones',\n",
    "                            trainable=True)\n",
    "            self.b = self.add_weight(name='b',\n",
    "                            shape=(self.m, self.n),\n",
    "                            initializer = keras.initializers.RandomUniform(minval=.7, maxval=1.3, seed=1),\n",
    "                            #initializer = 'ones',\n",
    "                            trainable=True)\n",
    "            self.c = self.add_weight(name='c',\n",
    "                            shape=(self.m, self.n),\n",
    "                            initializer = equally_spaced_initializer,\n",
    "                            #initializer = keras.initializers.RandomUniform(minval=-1.5, maxval=1.5, seed=1),\n",
    "                            #initializer = 'zeros',\n",
    "                            trainable=True)\n",
    "\n",
    "        elif self.memb_func == 'gaussian':\n",
    "            self.mu = self.add_weight(name='mu',\n",
    "                            shape=(self.m, self.n),\n",
    "                            initializer = equally_spaced_initializer,\n",
    "                            #initializer = keras.initializers.RandomUniform(minval=-1.5, maxval=1.5, seed=1),\n",
    "                            #initializer = 'zeros',\n",
    "                            trainable=True)\n",
    "            self.sigma = self.add_weight(name='sigma',\n",
    "                            shape=(self.m, self.n),\n",
    "                            initializer = keras.initializers.RandomUniform(minval=.7, maxval=1.3, seed=1),\n",
    "                            #initializer = 'ones',\n",
    "                            trainable=True)\n",
    "\n",
    "        elif self.memb_func == 'sigmoid':\n",
    "            self.gamma = self.add_weight(name = 'gamma',\n",
    "                            shape=(self.m, self.n),\n",
    "                            initializer = equally_spaced_initializer, #'ones',\n",
    "                            trainable = True)\n",
    "\n",
    "            self.c = self.add_weight(name = 'c',\n",
    "                            shape=(self.m, self.n),\n",
    "                            initializer = equally_spaced_initializer, #'ones',\n",
    "                            trainable = True)\n",
    "\n",
    "        super(FuzzyLayer, self).build(batch_input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x_inputs):\n",
    "        if self.memb_func == 'gbellmf':\n",
    "            Layer1 = 1/(1+\n",
    "                   tf.math.pow(\n",
    "                        tf.square(tf.subtract(\n",
    "                           tf.reshape(\n",
    "                               tf.tile(x_inputs, (1, self.m)), (-1, self.m, self.n))\n",
    "                           ,self.c\n",
    "                           ) / self.a)\n",
    "                        , self.b)\n",
    "                       )\n",
    "        elif self.memb_func == 'gaussian':\n",
    "            Layer1 = tf.exp(-1*\n",
    "                tf.square(tf.subtract(\n",
    "                    tf.reshape(\n",
    "                        tf.tile(x_inputs, (1, self.m)), (-1, self.m, self.n))\n",
    "                    ,self.mu\n",
    "                    )) / tf.square(self.sigma))\n",
    "\n",
    "        elif self.memb_func == 'sigmoid':\n",
    "            Layer1 = tf.math.divide(1,\n",
    "                        tf.math.exp(-self.gamma*\n",
    "                            tf.subtract(\n",
    "                               tf.reshape(\n",
    "                                   tf.tile(x_inputs, (1, self.m)), (-1, self.m, self.n))\n",
    "                                            ,self.c)\n",
    "                                    )\n",
    "                                    )\n",
    "        return Layer1  # = fuzzy cluster\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        # return ((self.batch_size, self.m, self.n))\n",
    "        return tf.TensorShape([self.batch_size, self.m, self.n])\n",
    "\n",
    "# Layer 2\n",
    "class RuleLayer(keras.layers.Layer):\n",
    "    def __init__(self, n_input, n_memb, **kwargs):\n",
    "        super(RuleLayer, self).__init__( **kwargs)\n",
    "        self.n = n_input\n",
    "        self.m = n_memb\n",
    "        self.batch_size = None\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.batch_size = batch_input_shape[0]\n",
    "        # self.batch_size = tf.shape(batch_input_shape)[0]\n",
    "        super(RuleLayer, self).build(batch_input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, input_):\n",
    "        CP = []\n",
    "        # a tensor object is not assignable*, so you cannot use it on the left-hand side of an assignment.\n",
    "        # build a Python list of tensors, and tf.stack() them together at the end of the loop:\n",
    "        for batch in range(self.batch_size):\n",
    "            xd_shape = [self.m]\n",
    "            c_shape = [1]\n",
    "            cp = input_[batch,:,0]\n",
    "\n",
    "            for d in range(1,self.n):\n",
    "                # append shape indizes\n",
    "                c_shape.insert(0,self.m)\n",
    "                xd_shape.insert(0,1)\n",
    "                # get cartesian product for each dimension\n",
    "                xd = tf.reshape(input_[batch,:,d], (xd_shape))\n",
    "                c = tf.reshape(cp,(c_shape))\n",
    "                cp = tf.matmul(c , xd)\n",
    "\n",
    "            flat_cp = tf.reshape(cp,(1, self.m**self.n))\n",
    "            CP.append(flat_cp)\n",
    "\n",
    "        return tf.reshape(tf.stack(CP), (self.batch_size, self.m**self.n))\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        if self.n == 1:\n",
    "            return tf.TensorShape([self.batch_size, self.m])\n",
    "        else:\n",
    "            return tf.TensorShape([self.batch_size, self.m** self.n])\n",
    "\n",
    "# Layer 3\n",
    "class NormLayer(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__( **kwargs)\n",
    "\n",
    "    def call(self, fire):\n",
    "        w_sum = tf.reshape(tf.reduce_sum(fire, axis=1), (-1,1))\n",
    "        w_norm = fire / w_sum\n",
    "        return w_norm\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "\n",
    "# Layer 4\n",
    "class DefuzzLayer(keras.layers.Layer):\n",
    "    def __init__(self, n_input, n_memb, **kwargs):\n",
    "        super().__init__( **kwargs)\n",
    "        self.n = n_input\n",
    "        self.m = n_memb\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.CP_bias = self.add_weight(name='Consequence_bias',\n",
    "                                                 shape=(1, self.m **self.n),\n",
    "                                                 initializer = keras.initializers.RandomUniform(minval=-2, maxval=2),\n",
    "                                                 # initializer = 'ones',\n",
    "                                                 trainable=True)\n",
    "        self.CP_weight = self.add_weight(name='Consequence_weight',\n",
    "                                            shape=(self.n, self.m ** self.n),\n",
    "                                            initializer = keras.initializers.RandomUniform(minval=-2, maxval=2),\n",
    "                                            # initializer = 'ones',\n",
    "                                            trainable=True)\n",
    "\n",
    "    def call(self, w_norm, Xs):\n",
    "\n",
    "        Layer4=tf.multiply(w_norm,\n",
    "                           tf.matmul(Xs, self.CP_weight) + self.CP_bias)\n",
    "        return Layer4  # Defuzzyfied Layer\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "\n",
    "# Layer 5\n",
    "class SummationLayer(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__( **kwargs)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.batch_size = batch_input_shape[0]\n",
    "        #self.batch_size = tf.shape(batch_input_shape)[0]\n",
    "        super(SummationLayer, self).build(batch_input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, Layer4):\n",
    "        output = tf.reduce_sum(Layer4, axis=1)\n",
    "        output = tf.reshape(output, (self.batch_size, 1))\n",
    "        return output # final output\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape([self.batch_size,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8388cf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.special\n",
    "\n",
    "def Func(x, y):\n",
    "    z = (np.sin(x) * np.exp((1 - np.cos(y)) ** 2) + np.cos(y) * np.exp((1 - np.sin(x)) ** 2) + (x - y) ** 2)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1ddb76a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 1258.2657 - val_loss: 1211.4744\n",
      "Epoch 2/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1173.0649 - val_loss: 1136.3475\n",
      "Epoch 3/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1103.4919 - val_loss: 1071.9127\n",
      "Epoch 4/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1043.6302 - val_loss: 1016.4278\n",
      "Epoch 5/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 992.4922 - val_loss: 969.5280\n",
      "Epoch 6/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 948.8751 - val_loss: 929.2832\n",
      "Epoch 7/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 912.2632 - val_loss: 895.9133\n",
      "Epoch 8/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 881.5729 - val_loss: 867.8094\n",
      "Epoch 9/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 855.8427 - val_loss: 844.4135\n",
      "Epoch 10/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 834.2520 - val_loss: 824.4515\n",
      "Epoch 11/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 815.9536 - val_loss: 807.6388\n",
      "Epoch 12/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 800.3891 - val_loss: 793.2076\n",
      "Epoch 13/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 787.0596 - val_loss: 780.8829\n",
      "Epoch 14/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 775.4824 - val_loss: 770.0490\n",
      "Epoch 15/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 765.3754 - val_loss: 760.6221\n",
      "Epoch 16/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 756.4584 - val_loss: 752.1425\n",
      "Epoch 17/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 748.3707 - val_loss: 744.4891\n",
      "Epoch 18/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 741.0665 - val_loss: 737.4802\n",
      "Epoch 19/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 734.3529 - val_loss: 731.0483\n",
      "Epoch 20/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 728.1838 - val_loss: 725.1805\n",
      "Epoch 21/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 722.5730 - val_loss: 719.7720\n",
      "Epoch 22/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 717.3695 - val_loss: 714.7302\n",
      "Epoch 23/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 712.4802 - val_loss: 710.0327\n",
      "Epoch 24/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 707.8788 - val_loss: 705.5696\n",
      "Epoch 25/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 703.5536 - val_loss: 701.3561\n",
      "Epoch 26/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 699.4118 - val_loss: 697.3416\n",
      "Epoch 27/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 695.4792 - val_loss: 693.4354\n",
      "Epoch 28/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 691.6685 - val_loss: 689.7417\n",
      "Epoch 29/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 688.0397 - val_loss: 686.1516\n",
      "Epoch 30/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 684.5178 - val_loss: 682.6902\n",
      "Epoch 31/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 681.1357 - val_loss: 679.3400\n",
      "Epoch 32/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 677.8546 - val_loss: 676.1248\n",
      "Epoch 33/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 674.6998 - val_loss: 673.0164\n",
      "Epoch 34/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 671.6666 - val_loss: 670.0395\n",
      "Epoch 35/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 668.6930 - val_loss: 667.1113\n",
      "Epoch 36/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 665.8267 - val_loss: 664.2930\n",
      "Epoch 37/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 663.0120 - val_loss: 661.5543\n",
      "Epoch 38/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 660.2681 - val_loss: 658.8584\n",
      "Epoch 39/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 657.6627 - val_loss: 656.2201\n",
      "Epoch 40/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 655.0303 - val_loss: 653.5905\n",
      "Epoch 41/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 652.4888 - val_loss: 651.0763\n",
      "Epoch 42/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 649.9844 - val_loss: 648.5981\n",
      "Epoch 43/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 647.5165 - val_loss: 646.1737\n",
      "Epoch 44/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 645.0969 - val_loss: 643.7551\n",
      "Epoch 45/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 642.7158 - val_loss: 641.3879\n",
      "Epoch 46/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 640.3691 - val_loss: 639.0676\n",
      "Epoch 47/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 638.0925 - val_loss: 636.8209\n",
      "Epoch 48/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 635.8677 - val_loss: 634.6204\n",
      "Epoch 49/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 633.6008 - val_loss: 632.4614\n",
      "Epoch 50/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 631.4979 - val_loss: 630.2734\n",
      "Epoch 51/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 629.3678 - val_loss: 628.1636\n",
      "Epoch 52/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 627.2502 - val_loss: 626.0709\n",
      "Epoch 53/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 625.1857 - val_loss: 624.0157\n",
      "Epoch 54/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 623.1477 - val_loss: 622.0182\n",
      "Epoch 55/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 621.1727 - val_loss: 620.0475\n",
      "Epoch 56/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 619.2416 - val_loss: 618.0707\n",
      "Epoch 57/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 617.2401 - val_loss: 616.1390\n",
      "Epoch 58/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 615.3330 - val_loss: 614.2828\n",
      "Epoch 59/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 613.5040 - val_loss: 612.4733\n",
      "Epoch 60/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 611.7081 - val_loss: 610.6815\n",
      "Epoch 61/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 609.9156 - val_loss: 608.9363\n",
      "Epoch 62/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 608.1334 - val_loss: 607.2551\n",
      "Epoch 63/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 606.4581 - val_loss: 605.5510\n",
      "Epoch 64/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 604.7579 - val_loss: 603.8503\n",
      "Epoch 65/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 603.1340 - val_loss: 602.1630\n",
      "Epoch 66/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 601.4894 - val_loss: 600.5414\n",
      "Epoch 67/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 599.8793 - val_loss: 598.9714\n",
      "Epoch 68/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 598.3027 - val_loss: 597.3724\n",
      "Epoch 69/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 596.6866 - val_loss: 595.8693\n",
      "Epoch 70/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 595.1978 - val_loss: 594.2550\n",
      "Epoch 71/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 593.6422 - val_loss: 592.8278\n",
      "Epoch 72/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 592.1851 - val_loss: 591.2899\n",
      "Epoch 73/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 590.6747 - val_loss: 589.8464\n",
      "Epoch 74/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 589.2772 - val_loss: 588.4069\n",
      "Epoch 75/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 587.8154 - val_loss: 587.0861\n",
      "Epoch 76/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 586.4627 - val_loss: 585.6566\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 2ms/step - loss: 585.0372 - val_loss: 584.3453\n",
      "Epoch 78/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 583.7117 - val_loss: 582.8706\n",
      "Epoch 79/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 582.2875 - val_loss: 581.6581\n",
      "Epoch 80/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 581.0604 - val_loss: 580.2413\n",
      "Epoch 81/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 579.7731 - val_loss: 578.9883\n",
      "Epoch 82/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 578.5133 - val_loss: 577.7099\n",
      "Epoch 83/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 577.2676 - val_loss: 576.4636\n",
      "Epoch 84/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 576.0007 - val_loss: 575.2540\n",
      "Epoch 85/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 574.8062 - val_loss: 574.0360\n",
      "Epoch 86/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 573.6235 - val_loss: 572.8651\n",
      "Epoch 87/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 572.4408 - val_loss: 571.7120\n",
      "Epoch 88/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 571.2963 - val_loss: 570.6532\n",
      "Epoch 89/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 570.1600 - val_loss: 569.4261\n",
      "Epoch 90/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 568.9993 - val_loss: 568.3627\n",
      "Epoch 91/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 567.8702 - val_loss: 567.2900\n",
      "Epoch 92/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 566.8244 - val_loss: 566.1588\n",
      "Epoch 93/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 565.7170 - val_loss: 565.0875\n",
      "Epoch 94/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 564.6748 - val_loss: 564.0541\n",
      "Epoch 95/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 563.6144 - val_loss: 563.0830\n",
      "Epoch 96/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 562.6258 - val_loss: 562.0330\n",
      "Epoch 97/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 561.6597 - val_loss: 560.9752\n",
      "Epoch 98/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 560.6110 - val_loss: 560.0757\n",
      "Epoch 99/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 559.6475 - val_loss: 559.0334\n",
      "Epoch 100/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 558.6345 - val_loss: 558.2323\n",
      "Epoch 101/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 557.7611 - val_loss: 557.1324\n",
      "Epoch 102/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 556.8269 - val_loss: 556.2595\n",
      "Epoch 103/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 555.9031 - val_loss: 555.3027\n",
      "Epoch 104/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 554.9489 - val_loss: 554.4276\n",
      "Epoch 105/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 554.0477 - val_loss: 553.5134\n",
      "Epoch 106/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 553.2003 - val_loss: 552.6303\n",
      "Epoch 107/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 552.3333 - val_loss: 551.7181\n",
      "Epoch 108/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 551.4756 - val_loss: 550.8954\n",
      "Epoch 109/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 550.6255 - val_loss: 550.0249\n",
      "Epoch 110/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 549.7614 - val_loss: 549.2072\n",
      "Epoch 111/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 548.9540 - val_loss: 548.3832\n",
      "Epoch 112/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 548.1340 - val_loss: 547.5788\n",
      "Epoch 113/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 547.3406 - val_loss: 546.8580\n",
      "Epoch 114/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 546.5561 - val_loss: 545.9996\n",
      "Epoch 115/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 545.7504 - val_loss: 545.2947\n",
      "Epoch 116/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 545.0231 - val_loss: 544.6353\n",
      "Epoch 117/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 544.2625 - val_loss: 543.8449\n",
      "Epoch 118/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 543.5640 - val_loss: 543.0649\n",
      "Epoch 119/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 542.7837 - val_loss: 542.4258\n",
      "Epoch 120/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 542.0938 - val_loss: 541.7181\n",
      "Epoch 121/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 541.4011 - val_loss: 540.9006\n",
      "Epoch 122/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 540.6973 - val_loss: 540.2055\n",
      "Epoch 123/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 540.0649 - val_loss: 539.5198\n",
      "Epoch 124/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 539.3591 - val_loss: 538.8445\n",
      "Epoch 125/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 538.6431 - val_loss: 538.2196\n",
      "Epoch 126/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 538.0111 - val_loss: 537.5516\n",
      "Epoch 127/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 537.3584 - val_loss: 537.0420\n",
      "Epoch 128/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 536.6802 - val_loss: 536.2856\n",
      "Epoch 129/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 536.0916 - val_loss: 535.7238\n",
      "Epoch 130/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 535.4751 - val_loss: 535.0869\n",
      "Epoch 131/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 534.8638 - val_loss: 534.3953\n",
      "Epoch 132/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 534.2773 - val_loss: 533.8009\n",
      "Epoch 133/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 533.6200 - val_loss: 533.1990\n",
      "Epoch 134/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 533.0475 - val_loss: 532.6068\n",
      "Epoch 135/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 532.4335 - val_loss: 532.0449\n",
      "Epoch 136/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 531.8649 - val_loss: 531.4461\n",
      "Epoch 137/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 531.3544 - val_loss: 530.8843\n",
      "Epoch 138/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 530.7794 - val_loss: 530.4186\n",
      "Epoch 139/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 530.2153 - val_loss: 529.7958\n",
      "Epoch 140/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 529.6500 - val_loss: 529.2966\n",
      "Epoch 141/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 529.1392 - val_loss: 528.6891\n",
      "Epoch 142/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 528.6091 - val_loss: 528.1746\n",
      "Epoch 143/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 528.1089 - val_loss: 527.6729\n",
      "Epoch 144/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 527.5752 - val_loss: 527.1338\n",
      "Epoch 145/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 527.0090 - val_loss: 526.7702\n",
      "Epoch 146/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 526.5574 - val_loss: 526.2335\n",
      "Epoch 147/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 526.0142 - val_loss: 525.6667\n",
      "Epoch 148/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 525.5874 - val_loss: 525.1608\n",
      "Epoch 149/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 525.0524 - val_loss: 524.6777\n",
      "Epoch 150/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 524.6385 - val_loss: 524.2224\n",
      "Epoch 151/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 524.1576 - val_loss: 523.7172\n",
      "Epoch 152/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 523.6578 - val_loss: 523.2496\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 2ms/step - loss: 523.1757 - val_loss: 522.8636\n",
      "Epoch 154/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 522.7446 - val_loss: 522.4133\n",
      "Epoch 155/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 522.2875 - val_loss: 521.8921\n",
      "Epoch 156/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 521.8629 - val_loss: 521.4583\n",
      "Epoch 157/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 521.4291 - val_loss: 521.0397\n",
      "Epoch 158/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 520.9592 - val_loss: 520.5776\n",
      "Epoch 159/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 520.5553 - val_loss: 520.1411\n",
      "Epoch 160/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 520.1006 - val_loss: 519.7669\n",
      "Epoch 161/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 519.7368 - val_loss: 519.3039\n",
      "Epoch 162/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 519.2731 - val_loss: 518.9423\n",
      "Epoch 163/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 518.8856 - val_loss: 518.5308\n",
      "Epoch 164/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 518.4973 - val_loss: 518.0946\n",
      "Epoch 165/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 518.0993 - val_loss: 517.6877\n",
      "Epoch 166/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 517.7063 - val_loss: 517.3029\n",
      "Epoch 167/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 517.3240 - val_loss: 517.0099\n",
      "Epoch 168/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 516.9512 - val_loss: 516.5550\n",
      "Epoch 169/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 516.4473 - val_loss: 516.2004\n",
      "Epoch 170/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 515.2921 - val_loss: 511.8792\n",
      "Epoch 171/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 511.3214 - val_loss: 510.3631\n",
      "Epoch 172/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 510.7954 - val_loss: 509.1157\n",
      "Epoch 173/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 509.4023 - val_loss: 508.2568\n",
      "Epoch 174/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 507.8583 - val_loss: 507.6831\n",
      "Epoch 175/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 508.5697 - val_loss: 507.2758\n",
      "Epoch 176/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 507.8962 - val_loss: 507.1105\n",
      "Epoch 177/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 506.9795 - val_loss: 508.0339\n",
      "Epoch 178/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 506.4413 - val_loss: 505.9495\n",
      "Epoch 179/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 506.5624 - val_loss: 505.1813\n",
      "Epoch 180/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 506.1945 - val_loss: 505.2361\n",
      "Epoch 181/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 505.2325 - val_loss: 504.2320\n",
      "Epoch 182/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 505.2177 - val_loss: 504.1927\n",
      "Epoch 183/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 504.6464 - val_loss: 503.6577\n",
      "Epoch 184/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 504.2325 - val_loss: 504.5901\n",
      "Epoch 185/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 503.5769 - val_loss: 507.4380\n",
      "Epoch 186/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 504.2510 - val_loss: 502.6096\n",
      "Epoch 187/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 503.1716 - val_loss: 502.3116\n",
      "Epoch 188/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 502.5967 - val_loss: 502.4175\n",
      "Epoch 189/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 502.2910 - val_loss: 503.3549\n",
      "Epoch 190/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 502.8326 - val_loss: 501.1677\n",
      "Epoch 191/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 502.1613 - val_loss: 501.3625\n",
      "Epoch 192/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 502.0361 - val_loss: 501.6735\n",
      "Epoch 193/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 501.6006 - val_loss: 500.5980\n",
      "Epoch 194/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 501.1772 - val_loss: 500.1439\n",
      "Epoch 195/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 500.8578 - val_loss: 501.9082\n",
      "Epoch 196/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 500.2389 - val_loss: 501.0465\n",
      "Epoch 197/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 500.0751 - val_loss: 498.9855\n",
      "Epoch 198/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 500.3323 - val_loss: 500.2799\n",
      "Epoch 199/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 499.4461 - val_loss: 499.2964\n",
      "Epoch 200/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 499.1084 - val_loss: 499.4714\n",
      "Epoch 201/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 499.0869 - val_loss: 497.8141\n",
      "Epoch 202/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 498.6360 - val_loss: 499.1295\n",
      "Epoch 203/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 497.9102 - val_loss: 497.3218\n",
      "Epoch 204/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 497.9614 - val_loss: 497.0839\n",
      "Epoch 205/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 497.9853 - val_loss: 496.9630\n",
      "Epoch 206/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 496.5515 - val_loss: 496.4905\n",
      "Epoch 207/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 496.9541 - val_loss: 497.5428\n",
      "Epoch 208/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 497.5741 - val_loss: 496.3175\n",
      "Epoch 209/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 497.0370 - val_loss: 496.0473\n",
      "Epoch 210/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 496.9615 - val_loss: 496.3704\n",
      "Epoch 211/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 496.3847 - val_loss: 496.4464\n",
      "Epoch 212/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 495.9362 - val_loss: 495.7082\n",
      "Epoch 213/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 496.5824 - val_loss: 494.8693\n",
      "Epoch 214/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 495.4398 - val_loss: 494.7018\n",
      "Epoch 215/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 495.1740 - val_loss: 495.7383\n",
      "Epoch 216/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 495.1310 - val_loss: 495.7562\n",
      "Epoch 217/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 494.7848 - val_loss: 494.0888\n",
      "Epoch 218/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 495.3843 - val_loss: 493.9517\n",
      "Epoch 219/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 493.9207 - val_loss: 493.6578\n",
      "Epoch 220/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 494.5409 - val_loss: 493.4656\n",
      "Epoch 221/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 494.2553 - val_loss: 493.2908\n",
      "Epoch 222/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 494.1245 - val_loss: 493.1992\n",
      "Epoch 223/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 493.2833 - val_loss: 492.5316\n",
      "Epoch 224/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 493.4189 - val_loss: 494.7634\n",
      "Epoch 225/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 493.3606 - val_loss: 492.1478\n",
      "Epoch 226/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 492.8712 - val_loss: 491.9353\n",
      "Epoch 227/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 493.0191 - val_loss: 491.8283\n",
      "Epoch 228/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 492.9141 - val_loss: 491.8156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 492.2621 - val_loss: 493.5402\n",
      "Epoch 230/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 492.1229 - val_loss: 493.4106\n",
      "Epoch 231/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 491.2975 - val_loss: 500.6134\n",
      "Epoch 232/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 492.0393 - val_loss: 491.1882\n",
      "Epoch 233/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 491.6190 - val_loss: 491.1480\n",
      "Epoch 234/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 491.6003 - val_loss: 490.1815\n",
      "Epoch 235/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 491.0247 - val_loss: 490.1818\n",
      "Epoch 236/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 490.7576 - val_loss: 489.8186\n",
      "Epoch 237/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 490.2968 - val_loss: 490.7993\n",
      "Epoch 238/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 490.6135 - val_loss: 489.9000\n",
      "Epoch 239/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 490.4048 - val_loss: 490.4268\n",
      "Epoch 240/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 490.0950 - val_loss: 490.8445\n",
      "Epoch 241/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 490.2224 - val_loss: 490.1771\n",
      "Epoch 242/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 489.7478 - val_loss: 488.8881\n",
      "Epoch 243/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 489.3995 - val_loss: 490.3470\n",
      "Epoch 244/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 489.1906 - val_loss: 491.7176\n",
      "Epoch 245/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 489.1703 - val_loss: 488.1435\n",
      "Epoch 246/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 489.0433 - val_loss: 488.1157\n",
      "Epoch 247/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 488.7770 - val_loss: 490.6202\n",
      "Epoch 248/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 488.8796 - val_loss: 488.3556\n",
      "Epoch 249/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 488.4433 - val_loss: 487.3980\n",
      "Epoch 250/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 489.1877 - val_loss: 488.7946\n",
      "Epoch 251/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 488.8438 - val_loss: 487.1487\n",
      "Epoch 252/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 487.4277 - val_loss: 488.9218\n",
      "Epoch 253/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 488.0764 - val_loss: 487.1710\n",
      "Epoch 254/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 487.4915 - val_loss: 488.0915\n",
      "Epoch 255/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 487.8312 - val_loss: 486.2844\n",
      "Epoch 256/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 487.1487 - val_loss: 486.1538\n",
      "Epoch 257/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 486.7431 - val_loss: 487.2762\n",
      "Epoch 258/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 486.7537 - val_loss: 487.0023\n",
      "Epoch 259/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 486.9381 - val_loss: 485.6087\n",
      "Epoch 260/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 486.6381 - val_loss: 485.6262\n",
      "Epoch 261/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 485.8941 - val_loss: 485.2566\n",
      "Epoch 262/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 485.6747 - val_loss: 487.4466\n",
      "Epoch 263/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 485.6760 - val_loss: 484.9739\n",
      "Epoch 264/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 486.4293 - val_loss: 485.0854\n",
      "Epoch 265/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 486.1623 - val_loss: 484.6985\n",
      "Epoch 266/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 485.5836 - val_loss: 486.0996\n",
      "Epoch 267/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 486.1129 - val_loss: 484.4595\n",
      "Epoch 268/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 485.2687 - val_loss: 484.5424\n",
      "Epoch 269/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 484.9203 - val_loss: 484.9619\n",
      "Epoch 270/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 485.1653 - val_loss: 483.9719\n",
      "Epoch 271/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 485.0558 - val_loss: 484.2017\n",
      "Epoch 272/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 484.5808 - val_loss: 483.4536\n",
      "Epoch 273/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 484.2180 - val_loss: 484.7463\n",
      "Epoch 274/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 484.3651 - val_loss: 483.4739\n",
      "Epoch 275/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 484.4572 - val_loss: 483.3015\n",
      "Epoch 276/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 484.3152 - val_loss: 483.1031\n",
      "Epoch 277/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 484.2575 - val_loss: 482.6810\n",
      "Epoch 278/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 483.5449 - val_loss: 482.9540\n",
      "Epoch 279/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 483.4339 - val_loss: 482.9749\n",
      "Epoch 280/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 483.3441 - val_loss: 482.9974\n",
      "Epoch 281/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 483.3503 - val_loss: 482.5896\n",
      "Epoch 282/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 483.1752 - val_loss: 482.0001\n",
      "Epoch 283/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 483.3666 - val_loss: 481.7618\n",
      "Epoch 284/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 483.2159 - val_loss: 482.1078\n",
      "Epoch 285/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 483.2638 - val_loss: 482.4949\n",
      "Epoch 286/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 482.6443 - val_loss: 481.3123\n",
      "Epoch 287/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 482.0768 - val_loss: 481.5017\n",
      "Epoch 288/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 482.0020 - val_loss: 481.5373\n",
      "Epoch 289/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 481.6719 - val_loss: 481.3120\n",
      "Epoch 290/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 482.0566 - val_loss: 480.9414\n",
      "Epoch 291/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 481.8814 - val_loss: 480.5936\n",
      "Epoch 292/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 481.7387 - val_loss: 482.4178\n",
      "Epoch 293/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 481.9984 - val_loss: 480.5873\n",
      "Epoch 294/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 481.4009 - val_loss: 480.1977\n",
      "Epoch 295/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 481.6304 - val_loss: 480.5186\n",
      "Epoch 296/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 481.2686 - val_loss: 480.0391\n",
      "Epoch 297/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 481.1125 - val_loss: 481.2085\n",
      "Epoch 298/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 480.9008 - val_loss: 481.2745\n",
      "Epoch 299/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 481.2379 - val_loss: 479.4936\n",
      "Epoch 300/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 480.0864 - val_loss: 479.3258\n",
      "Epoch 301/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 479.8043 - val_loss: 479.1534\n",
      "Epoch 302/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 480.2499 - val_loss: 479.0331\n",
      "Epoch 303/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 479.7589 - val_loss: 479.0680\n",
      "Epoch 304/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 479.7108 - val_loss: 479.6422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 479.3123 - val_loss: 478.7980\n",
      "Epoch 306/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 478.6333 - val_loss: 479.0485\n",
      "Epoch 307/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 479.1873 - val_loss: 478.7310\n",
      "Epoch 308/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 479.3586 - val_loss: 478.1764\n",
      "Epoch 309/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 479.5383 - val_loss: 478.4856\n",
      "Epoch 310/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 479.2465 - val_loss: 478.5356\n",
      "Epoch 311/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 478.9214 - val_loss: 477.8669\n",
      "Epoch 312/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 478.9430 - val_loss: 477.9029\n",
      "Epoch 313/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 479.1751 - val_loss: 477.9055\n",
      "Epoch 314/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 478.2619 - val_loss: 477.5213\n",
      "Epoch 315/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 478.7592 - val_loss: 477.2452\n",
      "Epoch 316/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 478.0710 - val_loss: 478.0858\n",
      "Epoch 317/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 478.3267 - val_loss: 477.0887\n",
      "Epoch 318/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 478.1226 - val_loss: 477.1169\n",
      "Epoch 319/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 478.1312 - val_loss: 476.7722\n",
      "Epoch 320/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 477.9597 - val_loss: 476.5440\n",
      "Epoch 321/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 477.5668 - val_loss: 476.6151\n",
      "Epoch 322/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 476.4290 - val_loss: 479.0238\n",
      "Epoch 323/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 477.3413 - val_loss: 476.3648\n",
      "Epoch 324/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 477.1744 - val_loss: 476.0478\n",
      "Epoch 325/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 477.0359 - val_loss: 476.7310\n",
      "Epoch 326/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 476.9554 - val_loss: 476.5027\n",
      "Epoch 327/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 476.7824 - val_loss: 475.7158\n",
      "Epoch 328/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 476.6769 - val_loss: 476.2073\n",
      "Epoch 329/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 476.3808 - val_loss: 475.7639\n",
      "Epoch 330/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 475.4012 - val_loss: 477.3802\n",
      "Epoch 331/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 476.5985 - val_loss: 475.4629\n",
      "Epoch 332/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 475.8954 - val_loss: 477.0747\n",
      "Epoch 333/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 475.7693 - val_loss: 475.6202\n",
      "Epoch 334/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 474.8492 - val_loss: 475.0461\n",
      "Epoch 335/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 476.0171 - val_loss: 475.2191\n",
      "Epoch 336/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 475.4853 - val_loss: 475.3818\n",
      "Epoch 337/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 475.6476 - val_loss: 475.0800\n",
      "Epoch 338/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 475.2072 - val_loss: 475.2003\n",
      "Epoch 339/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 475.6935 - val_loss: 474.4083\n",
      "Epoch 340/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 474.7812 - val_loss: 476.2765\n",
      "Epoch 341/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 475.3161 - val_loss: 473.9623\n",
      "Epoch 342/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 474.8224 - val_loss: 473.8775\n",
      "Epoch 343/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 474.5665 - val_loss: 474.9228\n",
      "Epoch 344/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 474.5020 - val_loss: 474.2542\n",
      "Epoch 345/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 474.8400 - val_loss: 473.4372\n",
      "Epoch 346/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 474.6032 - val_loss: 473.3456\n",
      "Epoch 347/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 474.0045 - val_loss: 474.0771\n",
      "Epoch 348/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 473.8863 - val_loss: 473.3730\n",
      "Epoch 349/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 474.0820 - val_loss: 472.9541\n",
      "Epoch 350/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 473.5011 - val_loss: 474.7631\n",
      "Epoch 351/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 473.6678 - val_loss: 473.2898\n",
      "Epoch 352/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 473.5199 - val_loss: 472.3864\n",
      "Epoch 353/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 473.6474 - val_loss: 472.6057\n",
      "Epoch 354/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 473.2526 - val_loss: 473.4044\n",
      "Epoch 355/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 473.0465 - val_loss: 472.2975\n",
      "Epoch 356/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 473.2996 - val_loss: 472.3830\n",
      "Epoch 357/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 473.3362 - val_loss: 472.2839\n",
      "Epoch 358/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 472.2656 - val_loss: 472.3905\n",
      "Epoch 359/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 472.5143 - val_loss: 472.4478\n",
      "Epoch 360/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 472.6744 - val_loss: 472.1985\n",
      "Epoch 361/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 472.3514 - val_loss: 471.3846\n",
      "Epoch 362/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 471.7242 - val_loss: 471.4803\n",
      "Epoch 363/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 472.1013 - val_loss: 472.2332\n",
      "Epoch 364/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 472.5960 - val_loss: 471.0642\n",
      "Epoch 365/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 471.9847 - val_loss: 470.9136\n",
      "Epoch 366/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 472.0308 - val_loss: 472.8474\n",
      "Epoch 367/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 471.8827 - val_loss: 471.2211\n",
      "Epoch 368/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 470.5955 - val_loss: 472.0446\n",
      "Epoch 369/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 470.6205 - val_loss: 470.4069\n",
      "Epoch 370/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 471.4392 - val_loss: 470.7166\n",
      "Epoch 371/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 471.3325 - val_loss: 470.9628\n",
      "Epoch 372/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 471.4403 - val_loss: 470.0172\n",
      "Epoch 373/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 470.6773 - val_loss: 473.2541\n",
      "Epoch 374/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 471.1605 - val_loss: 472.6996\n",
      "Epoch 375/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 470.7805 - val_loss: 470.0074\n",
      "Epoch 376/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 470.5951 - val_loss: 471.2432\n",
      "Epoch 377/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 470.5804 - val_loss: 470.5450\n",
      "Epoch 378/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 470.7086 - val_loss: 469.3596\n",
      "Epoch 379/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 470.0030 - val_loss: 469.8326\n",
      "Epoch 380/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 469.8946 - val_loss: 469.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 469.5886 - val_loss: 471.4488\n",
      "Epoch 382/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 470.6547 - val_loss: 469.2899\n",
      "Epoch 383/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 469.7155 - val_loss: 468.9489\n",
      "Epoch 384/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 469.5432 - val_loss: 468.8045\n",
      "Epoch 385/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 469.1768 - val_loss: 468.6950\n",
      "Epoch 386/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 469.1215 - val_loss: 470.2750\n",
      "Epoch 387/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 468.5823 - val_loss: 470.9316\n",
      "Epoch 388/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 469.3348 - val_loss: 468.3810\n",
      "Epoch 389/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 468.6748 - val_loss: 468.2505\n",
      "Epoch 390/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 469.6053 - val_loss: 467.9152\n",
      "Epoch 391/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.9757 - val_loss: 476.5728\n",
      "Epoch 392/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 468.6039 - val_loss: 467.6362\n",
      "Epoch 393/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 469.2415 - val_loss: 467.7241\n",
      "Epoch 394/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 468.0916 - val_loss: 467.5988\n",
      "Epoch 395/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 468.0440 - val_loss: 467.3745\n",
      "Epoch 396/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.9774 - val_loss: 467.7590\n",
      "Epoch 397/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.9629 - val_loss: 467.0510\n",
      "Epoch 398/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.9306 - val_loss: 467.0106\n",
      "Epoch 399/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.8562 - val_loss: 467.3155\n",
      "Epoch 400/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.4647 - val_loss: 468.3853\n",
      "Epoch 401/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.6968 - val_loss: 467.6334\n",
      "Epoch 402/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.0064 - val_loss: 466.4613\n",
      "Epoch 403/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.9930 - val_loss: 467.6463\n",
      "Epoch 404/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.6896 - val_loss: 466.3382\n",
      "Epoch 405/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.2318 - val_loss: 466.3698\n",
      "Epoch 406/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.3440 - val_loss: 466.3139\n",
      "Epoch 407/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.8326 - val_loss: 467.5945\n",
      "Epoch 408/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.4825 - val_loss: 466.4399\n",
      "Epoch 409/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.0328 - val_loss: 468.3018\n",
      "Epoch 410/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 467.0502 - val_loss: 466.1440\n",
      "Epoch 411/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.6071 - val_loss: 466.0336\n",
      "Epoch 412/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.8799 - val_loss: 465.7401\n",
      "Epoch 413/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.3379 - val_loss: 465.2574\n",
      "Epoch 414/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.4620 - val_loss: 465.1340\n",
      "Epoch 415/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.1304 - val_loss: 465.2864\n",
      "Epoch 416/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.0732 - val_loss: 465.2766\n",
      "Epoch 417/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 465.2821 - val_loss: 467.0344\n",
      "Epoch 418/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 466.2644 - val_loss: 464.8666\n",
      "Epoch 419/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 465.7455 - val_loss: 464.7049\n",
      "Epoch 420/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 465.9248 - val_loss: 464.5826\n",
      "Epoch 421/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 465.2430 - val_loss: 465.9818\n",
      "Epoch 422/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 465.5905 - val_loss: 464.9546\n",
      "Epoch 423/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 464.7598 - val_loss: 464.5804\n",
      "Epoch 424/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 465.0503 - val_loss: 464.0475\n",
      "Epoch 425/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 465.1878 - val_loss: 464.4515\n",
      "Epoch 426/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 464.9372 - val_loss: 464.8565\n",
      "Epoch 427/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 465.2766 - val_loss: 463.7100\n",
      "Epoch 428/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 464.4558 - val_loss: 463.5734\n",
      "Epoch 429/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 464.5334 - val_loss: 464.3669\n",
      "Epoch 430/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 464.3217 - val_loss: 464.5674\n",
      "Epoch 431/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.9539 - val_loss: 463.2316\n",
      "Epoch 432/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 464.2173 - val_loss: 463.2458\n",
      "Epoch 433/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.8555 - val_loss: 465.2916\n",
      "Epoch 434/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.3308 - val_loss: 465.1065\n",
      "Epoch 435/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 464.1269 - val_loss: 462.7967\n",
      "Epoch 436/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.7640 - val_loss: 462.7784\n",
      "Epoch 437/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.7141 - val_loss: 462.8750\n",
      "Epoch 438/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.4013 - val_loss: 462.7341\n",
      "Epoch 439/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 462.1854 - val_loss: 466.2008\n",
      "Epoch 440/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.4333 - val_loss: 463.8704\n",
      "Epoch 441/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.6804 - val_loss: 462.7835\n",
      "Epoch 442/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 463.0938 - val_loss: 462.2737\n",
      "Epoch 443/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 462.9596 - val_loss: 461.9823\n",
      "Epoch 444/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.0804 - val_loss: 463.0967\n",
      "Epoch 445/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 463.0188 - val_loss: 462.5642\n",
      "Epoch 446/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 462.7087 - val_loss: 461.6416\n",
      "Epoch 447/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 462.7794 - val_loss: 462.1418\n",
      "Epoch 448/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 462.6289 - val_loss: 461.4886\n",
      "Epoch 449/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 462.5991 - val_loss: 462.7661\n",
      "Epoch 450/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 462.4163 - val_loss: 463.3159\n",
      "Epoch 451/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 462.2668 - val_loss: 461.2019\n",
      "Epoch 452/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.8271 - val_loss: 461.5933\n",
      "Epoch 453/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 462.2243 - val_loss: 461.2119\n",
      "Epoch 454/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.3929 - val_loss: 460.7621\n",
      "Epoch 455/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.7993 - val_loss: 461.0100\n",
      "Epoch 456/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.2066 - val_loss: 461.0381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.5912 - val_loss: 461.1512\n",
      "Epoch 458/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.7198 - val_loss: 460.9000\n",
      "Epoch 459/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.2320 - val_loss: 460.7989\n",
      "Epoch 460/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.0680 - val_loss: 460.8555\n",
      "Epoch 461/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.2155 - val_loss: 460.1866\n",
      "Epoch 462/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.1687 - val_loss: 460.0013\n",
      "Epoch 463/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 460.6426 - val_loss: 461.5760\n",
      "Epoch 464/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.2025 - val_loss: 460.6758\n",
      "Epoch 465/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 460.6687 - val_loss: 460.1502\n",
      "Epoch 466/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 461.1311 - val_loss: 459.5930\n",
      "Epoch 467/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 460.4939 - val_loss: 459.4229\n",
      "Epoch 468/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 460.3648 - val_loss: 461.0224\n",
      "Epoch 469/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 459.7880 - val_loss: 459.4327\n",
      "Epoch 470/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 460.1942 - val_loss: 459.1845\n",
      "Epoch 471/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 459.5489 - val_loss: 459.3148\n",
      "Epoch 472/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 460.1563 - val_loss: 458.9526\n",
      "Epoch 473/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 459.0358 - val_loss: 459.1687\n",
      "Epoch 474/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 459.6257 - val_loss: 458.8671\n",
      "Epoch 475/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 459.5906 - val_loss: 460.0548\n",
      "Epoch 476/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 459.5653 - val_loss: 458.5855\n",
      "Epoch 477/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 459.8016 - val_loss: 458.3860\n",
      "Epoch 478/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 459.1779 - val_loss: 459.2965\n",
      "Epoch 479/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 459.0616 - val_loss: 459.6695\n",
      "Epoch 480/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.7839 - val_loss: 458.8707\n",
      "Epoch 481/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.9011 - val_loss: 458.0362\n",
      "Epoch 482/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.7764 - val_loss: 459.1205\n",
      "Epoch 483/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.9676 - val_loss: 458.3041\n",
      "Epoch 484/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.2961 - val_loss: 458.3199\n",
      "Epoch 485/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.6106 - val_loss: 457.5536\n",
      "Epoch 486/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.5069 - val_loss: 458.2979\n",
      "Epoch 487/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.1881 - val_loss: 457.3065\n",
      "Epoch 488/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.3512 - val_loss: 457.5593\n",
      "Epoch 489/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.1190 - val_loss: 459.1864\n",
      "Epoch 490/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.3994 - val_loss: 457.1371\n",
      "Epoch 491/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.2707 - val_loss: 456.9618\n",
      "Epoch 492/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.8665 - val_loss: 464.2894\n",
      "Epoch 493/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 457.9829 - val_loss: 456.6818\n",
      "Epoch 494/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 457.6959 - val_loss: 456.9221\n",
      "Epoch 495/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 457.7713 - val_loss: 456.5280\n",
      "Epoch 496/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 457.2010 - val_loss: 456.4708\n",
      "Epoch 497/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 458.0120 - val_loss: 456.4502\n",
      "Epoch 498/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.6952 - val_loss: 456.4867\n",
      "Epoch 499/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 457.1114 - val_loss: 456.4485\n",
      "Epoch 500/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 457.2401 - val_loss: 456.0401\n",
      "Epoch 501/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 457.0345 - val_loss: 456.1686\n",
      "Epoch 502/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.7047 - val_loss: 457.8900\n",
      "Epoch 503/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.8141 - val_loss: 455.7147\n",
      "Epoch 504/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.5319 - val_loss: 461.7660\n",
      "Epoch 505/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.4578 - val_loss: 455.6943\n",
      "Epoch 506/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.9092 - val_loss: 455.4568\n",
      "Epoch 507/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.0929 - val_loss: 455.4171\n",
      "Epoch 508/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.3612 - val_loss: 455.4915\n",
      "Epoch 509/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 456.4378 - val_loss: 456.5966\n",
      "Epoch 510/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 455.9327 - val_loss: 455.4262\n",
      "Epoch 511/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 455.4486 - val_loss: 460.2679\n",
      "Epoch 512/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 455.8375 - val_loss: 454.7968\n",
      "Epoch 513/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 455.3893 - val_loss: 454.9766\n",
      "Epoch 514/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 455.2909 - val_loss: 456.2723\n",
      "Epoch 515/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 455.6677 - val_loss: 454.6364\n",
      "Epoch 516/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 455.4056 - val_loss: 454.3992\n",
      "Epoch 517/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 455.1796 - val_loss: 454.3372\n",
      "Epoch 518/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 455.5563 - val_loss: 454.6984\n",
      "Epoch 519/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.9877 - val_loss: 454.3820\n",
      "Epoch 520/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.9247 - val_loss: 454.0826\n",
      "Epoch 521/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.1837 - val_loss: 453.8892\n",
      "Epoch 522/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.9662 - val_loss: 453.9786\n",
      "Epoch 523/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 455.0587 - val_loss: 453.7040\n",
      "Epoch 524/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.5347 - val_loss: 454.7089\n",
      "Epoch 525/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.7014 - val_loss: 453.5720\n",
      "Epoch 526/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.1062 - val_loss: 453.4297\n",
      "Epoch 527/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.3968 - val_loss: 453.5085\n",
      "Epoch 528/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.3435 - val_loss: 453.1966\n",
      "Epoch 529/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 453.7018 - val_loss: 454.2865\n",
      "Epoch 530/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.4258 - val_loss: 454.0131\n",
      "Epoch 531/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.4821 - val_loss: 452.9232\n",
      "Epoch 532/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.0683 - val_loss: 454.1750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 453.7329 - val_loss: 453.7166\n",
      "Epoch 534/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 454.1446 - val_loss: 453.9302\n",
      "Epoch 535/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 453.6533 - val_loss: 453.5060\n",
      "Epoch 536/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 453.1172 - val_loss: 454.7827\n",
      "Epoch 537/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 453.3862 - val_loss: 452.8794\n",
      "Epoch 538/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 453.5508 - val_loss: 452.4467\n",
      "Epoch 539/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.7515 - val_loss: 453.4706\n",
      "Epoch 540/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 453.1296 - val_loss: 452.4969\n",
      "Epoch 541/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.9452 - val_loss: 452.0464\n",
      "Epoch 542/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.7373 - val_loss: 452.7073\n",
      "Epoch 543/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.7317 - val_loss: 453.5041\n",
      "Epoch 544/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.4140 - val_loss: 452.7982\n",
      "Epoch 545/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.4216 - val_loss: 452.6045\n",
      "Epoch 546/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.7140 - val_loss: 451.6975\n",
      "Epoch 547/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.7941 - val_loss: 451.4215\n",
      "Epoch 548/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.3807 - val_loss: 451.5286\n",
      "Epoch 549/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.0386 - val_loss: 451.3061\n",
      "Epoch 550/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.2752 - val_loss: 452.5860\n",
      "Epoch 551/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.9708 - val_loss: 452.7766\n",
      "Epoch 552/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 452.3048 - val_loss: 451.4485\n",
      "Epoch 553/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.7398 - val_loss: 451.2201\n",
      "Epoch 554/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.7871 - val_loss: 450.9026\n",
      "Epoch 555/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.6581 - val_loss: 450.9604\n",
      "Epoch 556/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.4851 - val_loss: 450.9720\n",
      "Epoch 557/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.3717 - val_loss: 450.7505\n",
      "Epoch 558/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.6212 - val_loss: 450.3771\n",
      "Epoch 559/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.9081 - val_loss: 450.3571\n",
      "Epoch 560/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.1761 - val_loss: 455.7637\n",
      "Epoch 561/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 451.3260 - val_loss: 451.3990\n",
      "Epoch 562/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.6647 - val_loss: 450.2141\n",
      "Epoch 563/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.7306 - val_loss: 450.1342\n",
      "Epoch 564/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.4791 - val_loss: 450.9489\n",
      "Epoch 565/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.6838 - val_loss: 450.2502\n",
      "Epoch 566/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 450.6870 - val_loss: 450.2363\n",
      "Epoch 567/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.9172 - val_loss: 449.5583\n",
      "Epoch 568/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.0002 - val_loss: 450.6536\n",
      "Epoch 569/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.3904 - val_loss: 449.6024\n",
      "Epoch 570/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.6399 - val_loss: 451.2657\n",
      "Epoch 571/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.0002 - val_loss: 449.6550\n",
      "Epoch 572/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.9962 - val_loss: 449.3507\n",
      "Epoch 573/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.1972 - val_loss: 449.3485\n",
      "Epoch 574/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.7175 - val_loss: 449.0374\n",
      "Epoch 575/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.7284 - val_loss: 450.2256\n",
      "Epoch 576/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 450.2383 - val_loss: 448.8494\n",
      "Epoch 577/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.5542 - val_loss: 448.6332\n",
      "Epoch 578/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.3559 - val_loss: 448.7156\n",
      "Epoch 579/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.5329 - val_loss: 448.4585\n",
      "Epoch 580/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.5242 - val_loss: 448.7856\n",
      "Epoch 581/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.3573 - val_loss: 448.5801\n",
      "Epoch 582/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.1621 - val_loss: 448.4880\n",
      "Epoch 583/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.8755 - val_loss: 449.6682\n",
      "Epoch 584/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.8896 - val_loss: 448.7863\n",
      "Epoch 585/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.3615 - val_loss: 448.2442\n",
      "Epoch 586/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.6517 - val_loss: 447.8311\n",
      "Epoch 587/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 449.1430 - val_loss: 447.7589\n",
      "Epoch 588/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.6932 - val_loss: 449.6089\n",
      "Epoch 589/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.9171 - val_loss: 447.6390\n",
      "Epoch 590/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.2785 - val_loss: 447.6323\n",
      "Epoch 591/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.7166 - val_loss: 447.7220\n",
      "Epoch 592/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.9719 - val_loss: 448.2362\n",
      "Epoch 593/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.9730 - val_loss: 451.4844\n",
      "Epoch 594/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.1184 - val_loss: 447.2179\n",
      "Epoch 595/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.1299 - val_loss: 448.0491\n",
      "Epoch 596/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.9470 - val_loss: 447.3763\n",
      "Epoch 597/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 448.2235 - val_loss: 447.6136\n",
      "Epoch 598/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.4244 - val_loss: 448.9431\n",
      "Epoch 599/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.1270 - val_loss: 454.9198\n",
      "Epoch 600/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.9153 - val_loss: 447.6048\n",
      "Epoch 601/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.5392 - val_loss: 446.5413\n",
      "Epoch 602/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.1941 - val_loss: 446.4372\n",
      "Epoch 603/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.2534 - val_loss: 447.1254\n",
      "Epoch 604/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.0422 - val_loss: 449.2465\n",
      "Epoch 605/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.6548 - val_loss: 447.5481\n",
      "Epoch 606/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.3242 - val_loss: 446.0962\n",
      "Epoch 607/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.8571 - val_loss: 446.2625\n",
      "Epoch 608/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 447.0089 - val_loss: 446.5298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.5861 - val_loss: 447.4857\n",
      "Epoch 610/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.5777 - val_loss: 446.7601\n",
      "Epoch 611/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.9716 - val_loss: 445.7634\n",
      "Epoch 612/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.3771 - val_loss: 445.9181\n",
      "Epoch 613/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.2600 - val_loss: 446.2211\n",
      "Epoch 614/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.2694 - val_loss: 445.6926\n",
      "Epoch 615/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.4795 - val_loss: 445.4116\n",
      "Epoch 616/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.1885 - val_loss: 445.6880\n",
      "Epoch 617/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.9272 - val_loss: 446.6461\n",
      "Epoch 618/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.0456 - val_loss: 445.1736\n",
      "Epoch 619/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.9984 - val_loss: 446.1226\n",
      "Epoch 620/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 446.2824 - val_loss: 445.2974\n",
      "Epoch 621/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.6678 - val_loss: 444.8286\n",
      "Epoch 622/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.3929 - val_loss: 444.7504\n",
      "Epoch 623/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.5292 - val_loss: 445.5288\n",
      "Epoch 624/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.5291 - val_loss: 445.0035\n",
      "Epoch 625/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.4862 - val_loss: 444.5012\n",
      "Epoch 626/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.2812 - val_loss: 444.3706\n",
      "Epoch 627/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.4857 - val_loss: 444.8983\n",
      "Epoch 628/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.0084 - val_loss: 444.4048\n",
      "Epoch 629/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.1426 - val_loss: 444.2434\n",
      "Epoch 630/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.3025 - val_loss: 444.2950\n",
      "Epoch 631/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.5812 - val_loss: 445.2495\n",
      "Epoch 632/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.8409 - val_loss: 444.7317\n",
      "Epoch 633/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.4825 - val_loss: 444.2073\n",
      "Epoch 634/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 445.0540 - val_loss: 443.6836\n",
      "Epoch 635/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.5633 - val_loss: 443.8238\n",
      "Epoch 636/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.6115 - val_loss: 443.5137\n",
      "Epoch 637/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.3540 - val_loss: 444.0030\n",
      "Epoch 638/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.6566 - val_loss: 443.4066\n",
      "Epoch 639/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.2148 - val_loss: 443.9790\n",
      "Epoch 640/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.6950 - val_loss: 443.3022\n",
      "Epoch 641/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.3517 - val_loss: 443.5168\n",
      "Epoch 642/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.1031 - val_loss: 444.2744\n",
      "Epoch 643/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.9235 - val_loss: 445.0173\n",
      "Epoch 644/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.8535 - val_loss: 442.9377\n",
      "Epoch 645/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 444.1082 - val_loss: 442.8812\n",
      "Epoch 646/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.1479 - val_loss: 443.0012\n",
      "Epoch 647/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.5544 - val_loss: 442.9293\n",
      "Epoch 648/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.8907 - val_loss: 442.5821\n",
      "Epoch 649/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.1880 - val_loss: 442.8698\n",
      "Epoch 650/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.4146 - val_loss: 442.3717\n",
      "Epoch 651/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.5577 - val_loss: 443.5579\n",
      "Epoch 652/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.0663 - val_loss: 442.9843\n",
      "Epoch 653/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.9755 - val_loss: 442.1859\n",
      "Epoch 654/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.6595 - val_loss: 442.0908\n",
      "Epoch 655/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.5618 - val_loss: 441.9486\n",
      "Epoch 656/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.6765 - val_loss: 442.0213\n",
      "Epoch 657/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.4981 - val_loss: 441.9703\n",
      "Epoch 658/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 443.2254 - val_loss: 442.2209\n",
      "Epoch 659/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.8766 - val_loss: 441.7035\n",
      "Epoch 660/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.5027 - val_loss: 443.0381\n",
      "Epoch 661/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.4713 - val_loss: 441.7487\n",
      "Epoch 662/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.7515 - val_loss: 441.7382\n",
      "Epoch 663/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.9579 - val_loss: 441.8388\n",
      "Epoch 664/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.4887 - val_loss: 441.2841\n",
      "Epoch 665/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.8287 - val_loss: 441.3533\n",
      "Epoch 666/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.4492 - val_loss: 441.4836\n",
      "Epoch 667/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.0407 - val_loss: 441.2474\n",
      "Epoch 668/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.7394 - val_loss: 442.1494\n",
      "Epoch 669/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.6664 - val_loss: 441.8835\n",
      "Epoch 670/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 442.0345 - val_loss: 442.8925\n",
      "Epoch 671/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.9372 - val_loss: 441.1852\n",
      "Epoch 672/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.7206 - val_loss: 440.9656\n",
      "Epoch 673/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.3049 - val_loss: 440.5685\n",
      "Epoch 674/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.0844 - val_loss: 441.9239\n",
      "Epoch 675/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.3099 - val_loss: 442.3558\n",
      "Epoch 676/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.9370 - val_loss: 440.3687\n",
      "Epoch 677/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 441.2773 - val_loss: 440.2433\n",
      "Epoch 678/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.9180 - val_loss: 440.1802\n",
      "Epoch 679/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.9513 - val_loss: 440.3857\n",
      "Epoch 680/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.7332 - val_loss: 441.8755\n",
      "Epoch 681/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.9323 - val_loss: 440.0095\n",
      "Epoch 682/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.9383 - val_loss: 441.4738\n",
      "Epoch 683/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.8156 - val_loss: 439.7870\n",
      "Epoch 684/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.7227 - val_loss: 439.8971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.5796 - val_loss: 439.6428\n",
      "Epoch 686/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.4877 - val_loss: 440.5129\n",
      "Epoch 687/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.2250 - val_loss: 440.0110\n",
      "Epoch 688/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.4684 - val_loss: 439.8360\n",
      "Epoch 689/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 439.9080 - val_loss: 439.2960\n",
      "Epoch 690/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.9869 - val_loss: 439.3163\n",
      "Epoch 691/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.7991 - val_loss: 439.5870\n",
      "Epoch 692/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.8218 - val_loss: 439.1187\n",
      "Epoch 693/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.4293 - val_loss: 439.2230\n",
      "Epoch 694/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 440.1411 - val_loss: 438.9993\n",
      "Epoch 695/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.7835 - val_loss: 438.8480\n",
      "Epoch 696/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.6369 - val_loss: 439.7595\n",
      "Epoch 697/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.6484 - val_loss: 438.7209\n",
      "Epoch 698/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.7906 - val_loss: 438.6758\n",
      "Epoch 699/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.1970 - val_loss: 438.9316\n",
      "Epoch 700/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.3232 - val_loss: 438.5460\n",
      "Epoch 701/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.3910 - val_loss: 438.3997\n",
      "Epoch 702/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.9833 - val_loss: 440.2358\n",
      "Epoch 703/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.8375 - val_loss: 439.0003\n",
      "Epoch 704/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.9813 - val_loss: 438.2604\n",
      "Epoch 705/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.8900 - val_loss: 438.9710\n",
      "Epoch 706/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.6374 - val_loss: 440.5904\n",
      "Epoch 707/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.3929 - val_loss: 437.9591\n",
      "Epoch 708/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.8447 - val_loss: 438.0793\n",
      "Epoch 709/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.8912 - val_loss: 437.8845\n",
      "Epoch 710/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.2457 - val_loss: 441.6254\n",
      "Epoch 711/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 439.1581 - val_loss: 437.6970\n",
      "Epoch 712/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.6820 - val_loss: 437.6572\n",
      "Epoch 713/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.6064 - val_loss: 438.6042\n",
      "Epoch 714/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.5969 - val_loss: 437.4846\n",
      "Epoch 715/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.4073 - val_loss: 437.7205\n",
      "Epoch 716/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.5317 - val_loss: 437.9516\n",
      "Epoch 717/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.2545 - val_loss: 437.5232\n",
      "Epoch 718/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.2314 - val_loss: 437.3099\n",
      "Epoch 719/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 438.4311 - val_loss: 437.0869\n",
      "Epoch 720/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.5883 - val_loss: 438.8796\n",
      "Epoch 721/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.5651 - val_loss: 437.8271\n",
      "Epoch 722/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.7430 - val_loss: 437.3457\n",
      "Epoch 723/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.7958 - val_loss: 437.3208\n",
      "Epoch 724/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.7127 - val_loss: 436.7969\n",
      "Epoch 725/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.7652 - val_loss: 437.4424\n",
      "Epoch 726/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.9412 - val_loss: 436.5816\n",
      "Epoch 727/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.4703 - val_loss: 436.7822\n",
      "Epoch 728/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.3506 - val_loss: 436.4788\n",
      "Epoch 729/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.6247 - val_loss: 436.3516\n",
      "Epoch 730/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.0891 - val_loss: 436.6764\n",
      "Epoch 731/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.1319 - val_loss: 437.0284\n",
      "Epoch 732/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 437.1545 - val_loss: 436.3024\n",
      "Epoch 733/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.9756 - val_loss: 436.4452\n",
      "Epoch 734/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.5474 - val_loss: 436.3937\n",
      "Epoch 735/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.8362 - val_loss: 437.1436\n",
      "Epoch 736/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.5919 - val_loss: 436.2698\n",
      "Epoch 737/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.6173 - val_loss: 436.4226\n",
      "Epoch 738/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.4861 - val_loss: 435.7477\n",
      "Epoch 739/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.8539 - val_loss: 435.6522\n",
      "Epoch 740/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.6577 - val_loss: 436.2898\n",
      "Epoch 741/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.4644 - val_loss: 437.1428\n",
      "Epoch 742/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.2209 - val_loss: 435.6982\n",
      "Epoch 743/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.5525 - val_loss: 437.9347\n",
      "Epoch 744/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.1725 - val_loss: 437.3588\n",
      "Epoch 745/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.4124 - val_loss: 435.4087\n",
      "Epoch 746/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.9264 - val_loss: 435.6270\n",
      "Epoch 747/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.9588 - val_loss: 435.1133\n",
      "Epoch 748/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.8048 - val_loss: 436.8750\n",
      "Epoch 749/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.1533 - val_loss: 435.0294\n",
      "Epoch 750/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.5560 - val_loss: 435.3800\n",
      "Epoch 751/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 436.0641 - val_loss: 435.3077\n",
      "Epoch 752/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.9991 - val_loss: 435.0610\n",
      "Epoch 753/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.6212 - val_loss: 434.8366\n",
      "Epoch 754/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.7711 - val_loss: 434.7831\n",
      "Epoch 755/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.6746 - val_loss: 434.5530\n",
      "Epoch 756/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.4207 - val_loss: 434.4835\n",
      "Epoch 757/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.2397 - val_loss: 435.2599\n",
      "Epoch 758/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.2696 - val_loss: 434.5207\n",
      "Epoch 759/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.3169 - val_loss: 434.8207\n",
      "Epoch 760/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.3062 - val_loss: 434.2589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.7596 - val_loss: 435.6054\n",
      "Epoch 762/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 435.0154 - val_loss: 434.4456\n",
      "Epoch 763/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.9980 - val_loss: 434.0967\n",
      "Epoch 764/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.7640 - val_loss: 434.4673\n",
      "Epoch 765/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.8476 - val_loss: 434.5860\n",
      "Epoch 766/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.6589 - val_loss: 434.4048\n",
      "Epoch 767/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.6183 - val_loss: 433.8635\n",
      "Epoch 768/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.7202 - val_loss: 435.0379\n",
      "Epoch 769/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.8665 - val_loss: 433.6125\n",
      "Epoch 770/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.4515 - val_loss: 433.6099\n",
      "Epoch 771/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.4286 - val_loss: 433.5481\n",
      "Epoch 772/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.0016 - val_loss: 434.9640\n",
      "Epoch 773/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.5368 - val_loss: 435.2167\n",
      "Epoch 774/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.0958 - val_loss: 433.4787\n",
      "Epoch 775/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.2443 - val_loss: 433.4163\n",
      "Epoch 776/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.0615 - val_loss: 433.7609\n",
      "Epoch 777/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.3694 - val_loss: 433.4243\n",
      "Epoch 778/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 434.1909 - val_loss: 433.7686\n",
      "Epoch 779/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.8961 - val_loss: 433.3276\n",
      "Epoch 780/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.2513 - val_loss: 434.2499\n",
      "Epoch 781/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.0766 - val_loss: 433.0658\n",
      "Epoch 782/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.8420 - val_loss: 432.8748\n",
      "Epoch 783/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.8183 - val_loss: 432.7739\n",
      "Epoch 784/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.7022 - val_loss: 433.0819\n",
      "Epoch 785/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.3845 - val_loss: 432.5757\n",
      "Epoch 786/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.2947 - val_loss: 432.4864\n",
      "Epoch 787/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.2878 - val_loss: 432.7130\n",
      "Epoch 788/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.0779 - val_loss: 432.7654\n",
      "Epoch 789/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.2382 - val_loss: 433.9771\n",
      "Epoch 790/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.1683 - val_loss: 433.2809\n",
      "Epoch 791/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 433.2391 - val_loss: 432.1666\n",
      "Epoch 792/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.8616 - val_loss: 432.1547\n",
      "Epoch 793/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.5743 - val_loss: 436.1160\n",
      "Epoch 794/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.8463 - val_loss: 432.0219\n",
      "Epoch 795/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.4412 - val_loss: 436.3240\n",
      "Epoch 796/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.4737 - val_loss: 432.4684\n",
      "Epoch 797/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.8056 - val_loss: 432.2583\n",
      "Epoch 798/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.7599 - val_loss: 431.7629\n",
      "Epoch 799/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.4594 - val_loss: 431.7443\n",
      "Epoch 800/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.5515 - val_loss: 431.8244\n",
      "Epoch 801/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.0016 - val_loss: 435.5202\n",
      "Epoch 802/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.2781 - val_loss: 434.1270\n",
      "Epoch 803/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.8486 - val_loss: 431.4019\n",
      "Epoch 804/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.2902 - val_loss: 432.1324\n",
      "Epoch 805/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.0474 - val_loss: 432.1682\n",
      "Epoch 806/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.0414 - val_loss: 431.2511\n",
      "Epoch 807/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.0453 - val_loss: 431.4701\n",
      "Epoch 808/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.2261 - val_loss: 431.4684\n",
      "Epoch 809/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 432.1099 - val_loss: 431.0709\n",
      "Epoch 810/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.9020 - val_loss: 431.0931\n",
      "Epoch 811/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.9927 - val_loss: 430.9565\n",
      "Epoch 812/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.6156 - val_loss: 432.0763\n",
      "Epoch 813/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.3245 - val_loss: 432.0158\n",
      "Epoch 814/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.8671 - val_loss: 430.8083\n",
      "Epoch 815/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.6388 - val_loss: 431.2791\n",
      "Epoch 816/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.2761 - val_loss: 431.2306\n",
      "Epoch 817/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 431.8174 - val_loss: 430.5868\n",
      "Epoch 818/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.3150 - val_loss: 430.5038\n",
      "Epoch 819/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.4854 - val_loss: 430.4717\n",
      "Epoch 820/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.9183 - val_loss: 430.3622\n",
      "Epoch 821/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.9518 - val_loss: 431.4572\n",
      "Epoch 822/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.5238 - val_loss: 430.2386\n",
      "Epoch 823/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.2687 - val_loss: 430.8357\n",
      "Epoch 824/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.7130 - val_loss: 430.4479\n",
      "Epoch 825/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.6699 - val_loss: 430.7804\n",
      "Epoch 826/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.2666 - val_loss: 430.0511\n",
      "Epoch 827/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.9516 - val_loss: 429.9576\n",
      "Epoch 828/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 431.1155 - val_loss: 430.1811\n",
      "Epoch 829/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.4878 - val_loss: 430.3987\n",
      "Epoch 830/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.4602 - val_loss: 430.0067\n",
      "Epoch 831/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.6776 - val_loss: 429.7349\n",
      "Epoch 832/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.4589 - val_loss: 429.8694\n",
      "Epoch 833/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.4053 - val_loss: 430.1776\n",
      "Epoch 834/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.5096 - val_loss: 429.5334\n",
      "Epoch 835/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.7224 - val_loss: 429.5279\n",
      "Epoch 836/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.0655 - val_loss: 429.7006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.6559 - val_loss: 430.0206\n",
      "Epoch 838/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.3552 - val_loss: 429.4695\n",
      "Epoch 839/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.5240 - val_loss: 429.8809\n",
      "Epoch 840/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.3467 - val_loss: 429.2860\n",
      "Epoch 841/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.8545 - val_loss: 429.1744\n",
      "Epoch 842/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.5105 - val_loss: 429.2553\n",
      "Epoch 843/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 430.1172 - val_loss: 429.1915\n",
      "Epoch 844/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.7013 - val_loss: 429.4795\n",
      "Epoch 845/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.9301 - val_loss: 428.8975\n",
      "Epoch 846/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.8066 - val_loss: 428.9652\n",
      "Epoch 847/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.7216 - val_loss: 429.2597\n",
      "Epoch 848/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.6547 - val_loss: 429.0316\n",
      "Epoch 849/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.8185 - val_loss: 428.8918\n",
      "Epoch 850/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.4219 - val_loss: 429.7544\n",
      "Epoch 851/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.5688 - val_loss: 429.1289\n",
      "Epoch 852/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.3611 - val_loss: 428.9958\n",
      "Epoch 853/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.5473 - val_loss: 429.4026\n",
      "Epoch 854/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.3015 - val_loss: 429.4564\n",
      "Epoch 855/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.2346 - val_loss: 428.6187\n",
      "Epoch 856/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.4269 - val_loss: 428.2433\n",
      "Epoch 857/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 428.7032 - val_loss: 428.5164\n",
      "Epoch 858/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.2380 - val_loss: 428.1536\n",
      "Epoch 859/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.1712 - val_loss: 428.8261\n",
      "Epoch 860/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.2008 - val_loss: 428.0993\n",
      "Epoch 861/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.5103 - val_loss: 428.3606\n",
      "Epoch 862/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.2328 - val_loss: 428.1349\n",
      "Epoch 863/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.2776 - val_loss: 429.2928\n",
      "Epoch 864/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.2184 - val_loss: 429.0193\n",
      "Epoch 865/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 429.1823 - val_loss: 428.3794\n",
      "Epoch 866/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.5066 - val_loss: 429.1114\n",
      "Epoch 867/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.4681 - val_loss: 427.6960\n",
      "Epoch 868/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.5529 - val_loss: 427.6855\n",
      "Epoch 869/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.0082 - val_loss: 427.8064\n",
      "Epoch 870/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.3773 - val_loss: 427.6005\n",
      "Epoch 871/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.7806 - val_loss: 427.8958\n",
      "Epoch 872/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.1255 - val_loss: 428.0425\n",
      "Epoch 873/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.5500 - val_loss: 427.3015\n",
      "Epoch 874/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.9065 - val_loss: 428.8546\n",
      "Epoch 875/1000\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 427.5458 - val_loss: 427.2221\n",
      "Epoch 876/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.0012 - val_loss: 427.2463\n",
      "Epoch 877/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.7546 - val_loss: 427.4669\n",
      "Epoch 878/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.0113 - val_loss: 427.0569\n",
      "Epoch 879/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.1258 - val_loss: 427.0269\n",
      "Epoch 880/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 428.3963 - val_loss: 427.7595\n",
      "Epoch 881/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 427.7918 - val_loss: 427.6262\n",
      "Epoch 882/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 427.4575 - val_loss: 427.1240\n",
      "Epoch 883/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.8025 - val_loss: 426.7885\n",
      "Epoch 884/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.8438 - val_loss: 427.3513\n",
      "Epoch 885/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.6554 - val_loss: 427.2028\n",
      "Epoch 886/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.6164 - val_loss: 426.6418\n",
      "Epoch 887/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.3421 - val_loss: 426.9105\n",
      "Epoch 888/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.7080 - val_loss: 426.7730\n",
      "Epoch 889/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.5181 - val_loss: 427.0370\n",
      "Epoch 890/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.4327 - val_loss: 428.5030\n",
      "Epoch 891/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.2230 - val_loss: 426.5602\n",
      "Epoch 892/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.2433 - val_loss: 426.5593\n",
      "Epoch 893/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.1245 - val_loss: 426.3943\n",
      "Epoch 894/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.0489 - val_loss: 426.1840\n",
      "Epoch 895/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.3821 - val_loss: 426.4271\n",
      "Epoch 896/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.4439 - val_loss: 427.4586\n",
      "Epoch 897/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 427.0892 - val_loss: 426.2262\n",
      "Epoch 898/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.7099 - val_loss: 426.4848\n",
      "Epoch 899/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.9695 - val_loss: 425.9286\n",
      "Epoch 900/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.4907 - val_loss: 426.1177\n",
      "Epoch 901/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.5307 - val_loss: 426.4268\n",
      "Epoch 902/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.3275 - val_loss: 426.0797\n",
      "Epoch 903/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.3704 - val_loss: 427.1498\n",
      "Epoch 904/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.6354 - val_loss: 425.7646\n",
      "Epoch 905/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.3453 - val_loss: 425.6092\n",
      "Epoch 906/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.5066 - val_loss: 426.4413\n",
      "Epoch 907/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.3624 - val_loss: 425.4876\n",
      "Epoch 908/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.3971 - val_loss: 425.6851\n",
      "Epoch 909/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.5782 - val_loss: 426.0704\n",
      "Epoch 910/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.0778 - val_loss: 425.5519\n",
      "Epoch 911/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.2614 - val_loss: 426.8582\n",
      "Epoch 912/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.0464 - val_loss: 426.2707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.8354 - val_loss: 425.2054\n",
      "Epoch 914/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.0456 - val_loss: 425.1134\n",
      "Epoch 915/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.2199 - val_loss: 425.4719\n",
      "Epoch 916/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.5222 - val_loss: 425.0550\n",
      "Epoch 917/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.8841 - val_loss: 425.1843\n",
      "Epoch 918/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.5645 - val_loss: 425.8625\n",
      "Epoch 919/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 426.1813 - val_loss: 424.8706\n",
      "Epoch 920/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.5682 - val_loss: 425.6050\n",
      "Epoch 921/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.6942 - val_loss: 424.7816\n",
      "Epoch 922/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.6056 - val_loss: 425.3144\n",
      "Epoch 923/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.3709 - val_loss: 426.0521\n",
      "Epoch 924/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.2809 - val_loss: 424.8036\n",
      "Epoch 925/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.4077 - val_loss: 424.7433\n",
      "Epoch 926/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.4010 - val_loss: 424.6412\n",
      "Epoch 927/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.5429 - val_loss: 425.4305\n",
      "Epoch 928/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.4779 - val_loss: 424.4495\n",
      "Epoch 929/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.3585 - val_loss: 424.6592\n",
      "Epoch 930/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.3247 - val_loss: 424.4844\n",
      "Epoch 931/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.0490 - val_loss: 424.4886\n",
      "Epoch 932/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.1891 - val_loss: 424.3321\n",
      "Epoch 933/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.0581 - val_loss: 424.4294\n",
      "Epoch 934/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.9088 - val_loss: 424.5297\n",
      "Epoch 935/1000\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 424.8929 - val_loss: 424.1259\n",
      "Epoch 936/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.5355 - val_loss: 425.0443\n",
      "Epoch 937/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.2394 - val_loss: 424.7870\n",
      "Epoch 938/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.8444 - val_loss: 424.6326\n",
      "Epoch 939/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.9218 - val_loss: 423.8883\n",
      "Epoch 940/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.6258 - val_loss: 424.3173\n",
      "Epoch 941/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 425.0389 - val_loss: 423.8462\n",
      "Epoch 942/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.6787 - val_loss: 424.1699\n",
      "Epoch 943/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.8957 - val_loss: 423.9597\n",
      "Epoch 944/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.2020 - val_loss: 424.3117\n",
      "Epoch 945/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.5939 - val_loss: 423.6271\n",
      "Epoch 946/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.0127 - val_loss: 423.6447\n",
      "Epoch 947/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.1683 - val_loss: 423.4913\n",
      "Epoch 948/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.4728 - val_loss: 423.6543\n",
      "Epoch 949/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.5851 - val_loss: 423.5425\n",
      "Epoch 950/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.7920 - val_loss: 426.0013\n",
      "Epoch 951/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.1322 - val_loss: 423.3384\n",
      "Epoch 952/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.7569 - val_loss: 423.8057\n",
      "Epoch 953/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.4578 - val_loss: 423.2560\n",
      "Epoch 954/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.4666 - val_loss: 423.3407\n",
      "Epoch 955/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.5982 - val_loss: 423.3687\n",
      "Epoch 956/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.6609 - val_loss: 423.3563\n",
      "Epoch 957/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.7014 - val_loss: 423.0584\n",
      "Epoch 958/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 424.1494 - val_loss: 423.0388\n",
      "Epoch 959/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.9721 - val_loss: 423.3333\n",
      "Epoch 960/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.9395 - val_loss: 423.1153\n",
      "Epoch 961/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.4519 - val_loss: 423.0181\n",
      "Epoch 962/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.5807 - val_loss: 422.8318\n",
      "Epoch 963/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.9005 - val_loss: 422.7365\n",
      "Epoch 964/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.0486 - val_loss: 423.2172\n",
      "Epoch 965/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.3182 - val_loss: 423.3788\n",
      "Epoch 966/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.7405 - val_loss: 422.6357\n",
      "Epoch 967/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.7083 - val_loss: 422.6497\n",
      "Epoch 968/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.4300 - val_loss: 423.1808\n",
      "Epoch 969/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.1148 - val_loss: 423.5053\n",
      "Epoch 970/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.6968 - val_loss: 423.0722\n",
      "Epoch 971/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.2308 - val_loss: 422.3754\n",
      "Epoch 972/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.9861 - val_loss: 422.5951\n",
      "Epoch 973/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.3301 - val_loss: 422.3257\n",
      "Epoch 974/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.1458 - val_loss: 422.4767\n",
      "Epoch 975/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.9018 - val_loss: 422.4117\n",
      "Epoch 976/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.1042 - val_loss: 422.1750\n",
      "Epoch 977/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.8477 - val_loss: 422.1485\n",
      "Epoch 978/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.9710 - val_loss: 422.0747\n",
      "Epoch 979/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.6090 - val_loss: 422.5081\n",
      "Epoch 980/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.4260 - val_loss: 423.6830\n",
      "Epoch 981/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 423.2826 - val_loss: 422.0695\n",
      "Epoch 982/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.8064 - val_loss: 423.1305\n",
      "Epoch 983/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.7144 - val_loss: 422.0925\n",
      "Epoch 984/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.7725 - val_loss: 422.4088\n",
      "Epoch 985/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.9139 - val_loss: 421.7433\n",
      "Epoch 986/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.6371 - val_loss: 421.9024\n",
      "Epoch 987/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.6074 - val_loss: 422.1432\n",
      "Epoch 988/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.3915 - val_loss: 422.5978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.1420 - val_loss: 421.7935\n",
      "Epoch 990/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.3930 - val_loss: 421.5430\n",
      "Epoch 991/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.4421 - val_loss: 421.4875\n",
      "Epoch 992/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.2074 - val_loss: 421.7827\n",
      "Epoch 993/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.0463 - val_loss: 421.3877\n",
      "Epoch 994/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.5646 - val_loss: 421.3799\n",
      "Epoch 995/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.2714 - val_loss: 421.4334\n",
      "Epoch 996/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.0880 - val_loss: 422.6993\n",
      "Epoch 997/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.3510 - val_loss: 421.3490\n",
      "Epoch 998/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 422.1694 - val_loss: 421.1802\n",
      "Epoch 999/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 421.8637 - val_loss: 421.7545\n",
      "Epoch 1000/1000\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 421.9061 - val_loss: 422.3629\n",
      "Model: \"myanfis\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputLayer (InputLayer)        [(16, 2)]            0           []                               \n",
      "                                                                                                  \n",
      " fuzzyLayer (FuzzyLayer)        (16, 2, 2)           8           ['inputLayer[0][0]']             \n",
      "                                                                                                  \n",
      " ruleLayer (RuleLayer)          (16, 4)              0           ['fuzzyLayer[0][0]']             \n",
      "                                                                                                  \n",
      " normLayer (NormLayer)          (16, 4)              0           ['ruleLayer[0][0]']              \n",
      "                                                                                                  \n",
      " defuzzLayer (DefuzzLayer)      (16, 4)              12          ['normLayer[0][0]',              \n",
      "                                                                  'inputLayer[0][0]']             \n",
      "                                                                                                  \n",
      " sumLayer (SummationLayer)      (16, 1)              0           ['defuzzLayer[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "param = fis_parameters(\n",
    "        n_input = 2,                # no. of Regressors\n",
    "        n_memb = 2,                 # no. of fuzzy memberships\n",
    "        batch_size = 16,            # 16 / 32 / 64 / ...\n",
    "        memb_func = 'gaussian',      # 'gaussian' / 'gbellmf' / 'sigmoid'\n",
    "        optimizer = 'adam',          # sgd / adam / ...\n",
    "        loss = 'mse',               # mse / mae / huber_loss / mean_absolute_percentage_error / ...\n",
    "        n_epochs = 1000              # 10 / 25 / 50 / 100 / ...\n",
    "        )\n",
    "    # create random data\n",
    "#X_train = np.random.rand(param.batch_size*5, param.n_input),\n",
    "#X_test = np.random.rand(param.batch_size*2, param.n_input)\n",
    "#y_train = np.random.rand(param.batch_size*5,1),\n",
    "#y_test = np.random.rand(param.batch_size*2, 1)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "d = 10\n",
    "\n",
    "for x in range(-5*d, 5*d):\n",
    "    for y in range(-5*d, 5*d):\n",
    "        X_train += [[x/d, y/d]]\n",
    "        y_train += [Func(x/d, y/d)]\n",
    "        \n",
    "for x in range(-5*d, 5*d):\n",
    "    for y in range(-5*d, 5*d):\n",
    "        X_test += [[x/d, y/d]]\n",
    "        y_test += [Func(x/d, y/d)]\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "fis = ANFIS(n_input = param.n_input,\n",
    "                    n_memb = param.n_memb,\n",
    "                    batch_size = param.batch_size,\n",
    "                    memb_func = param.memb_func,\n",
    "                    name = 'myanfis'\n",
    "                    )\n",
    "\n",
    "    # compile model\n",
    "fis.model.compile(optimizer=param.optimizer,\n",
    "                loss=param.loss\n",
    "                #,metrics=['mse']  # ['mae', 'mse']\n",
    "                )\n",
    "\n",
    "    # fit model\n",
    "history = fis.fit(X_train, y_train,\n",
    "                epochs=param.n_epochs,\n",
    "                batch_size=param.batch_size,\n",
    "                validation_data = (X_test, y_test),\n",
    "                # callbacks = [tensorboard_callback]  # for tensorboard\n",
    "                )\n",
    "\n",
    "    # eval model\n",
    "import pandas as pd\n",
    "fis.plotmfs(show_initial_weights=True)\n",
    "\n",
    "loss_curves = pd.DataFrame(history.history)\n",
    "loss_curves.plot(figsize=(8, 5))\n",
    "\n",
    "fis.model.summary()\n",
    "\n",
    "# get premise parameters\n",
    "premise_parameters = fis.model.get_layer('fuzzyLayer').get_weights()       # alternative\n",
    "\n",
    "    # get consequence paramters\n",
    "bias = fis.bias\n",
    "weights = fis.weights\n",
    "    # conseq_parameters = fis.model.get_layer('defuzzLayer').get_weights()       # alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "02535f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.5429006],\n",
       "       [ -4.987119 ],\n",
       "       [ -4.4311514],\n",
       "       ...,\n",
       "       [-23.409588 ],\n",
       "       [-20.772228 ],\n",
       "       [-18.476166 ]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fis(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "97a579a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x220f1108310>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], y_test, c='blue', marker='o')\n",
    "result_set = fis(X_train)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], result_set, c='red', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc880b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
