{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76052281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7015633532145818233\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.special\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "db09e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Func(x, y):\n",
    "    z = (np.sin(x) * np.exp((1 - np.cos(y)) ** 2) + np.cos(y) * np.exp((1 - np.sin(x)) ** 2) + (x - y) ** 2)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "149fe722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 50)                150       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, input_dim=2, activation=\"sigmoid\", kernel_initializer=\"random_normal\", use_bias=True))\n",
    "model.add(Dense(1, activation=\"linear\", kernel_initializer=\"random_normal\", use_bias=False))\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.005, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=sgd, metrics=[\"mse\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2cc00123",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_set=[]\n",
    "z_set = []\n",
    "d=10\n",
    "for x in range(-5*d,5*d):\n",
    "    for y in range(-5*d,5*d):\n",
    "       xy_set+=[[x/d, y/d]] \n",
    "       z_set+=[Func(x/d, y/d)] \n",
    "\n",
    "xy_set = np.array(xy_set)\n",
    "z_set = np.array(z_set)\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')         \n",
    "        \n",
    "ax.scatter(xy_set[:,0], xy_set[:,1], z_set, c='blue', marker='o')  \n",
    "plt.pause(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e9967a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        plt.clf()\n",
    "        \n",
    "        xy_set = []\n",
    "        z_set = []\n",
    "        d = 10\n",
    "        \n",
    "        for x in range(-5*d, 5*d):\n",
    "            for y in range(-5*d, 5*d):\n",
    "                xy_set += [[x/d, y/d]]\n",
    "                z_set += [Func(x/d, y/d)]\n",
    "                \n",
    "        xy_set = np.array(xy_set)\n",
    "        z_set = np.array(z_set)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.scatter(xy_set[:, 0], xy_set[:, 1], z_set, c='blue', marker='o')\n",
    "        result_set = model.predict(xy_set)\n",
    "        ax.scatter(xy_set[:, 0], xy_set[:, 1], result_set, c='red', marker='o')\n",
    "        plt.pause(5)\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bd883564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compress(x):\n",
    "    return (x / (np.amax(x) - np.amin(x)))\n",
    "def Decompress(x):\n",
    "    return (x) * parange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ce015ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 1s 829us/step - loss: 862.5048 - mse: 862.5048\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 1s 795us/step - loss: 532.0420 - mse: 532.0420\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 1s 864us/step - loss: 401.5183 - mse: 401.5183\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 1s 813us/step - loss: 321.8166 - mse: 321.8166\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 278.4623 - mse: 278.4623\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 1s 807us/step - loss: 254.5137 - mse: 254.5137\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 1s 816us/step - loss: 238.4993 - mse: 238.4993\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 1s 811us/step - loss: 227.6241 - mse: 227.6241\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 1s 762us/step - loss: 221.4149 - mse: 221.4149\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 1s 816us/step - loss: 217.1495 - mse: 217.1495\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 1s 754us/step - loss: 215.1421 - mse: 215.1421\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 1s 787us/step - loss: 208.1729 - mse: 208.1729\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 1s 753us/step - loss: 202.6921 - mse: 202.6921\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 1s 772us/step - loss: 202.3485 - mse: 202.3485\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 1s 798us/step - loss: 199.2107 - mse: 199.2107\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 1s 759us/step - loss: 195.9571 - mse: 195.9571\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 1s 760us/step - loss: 197.6706 - mse: 197.6705\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 1s 757us/step - loss: 197.0995 - mse: 197.0995\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 1s 792us/step - loss: 195.6788 - mse: 195.6788\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 1s 757us/step - loss: 192.2555 - mse: 192.2555\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 1s 779us/step - loss: 193.4120 - mse: 193.4120\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 1s 771us/step - loss: 190.7461 - mse: 190.7461\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 1s 790us/step - loss: 186.8464 - mse: 186.8464\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 1s 869us/step - loss: 187.0309 - mse: 187.0309\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 1s 979us/step - loss: 184.4834 - mse: 184.4834\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 1s 796us/step - loss: 185.3312 - mse: 185.3312\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 1s 778us/step - loss: 184.4152 - mse: 184.4152\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 1s 773us/step - loss: 182.8385 - mse: 182.8385\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 1s 766us/step - loss: 184.5163 - mse: 184.5163\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 1s 744us/step - loss: 183.8325 - mse: 183.8325\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 1s 765us/step - loss: 181.0634 - mse: 181.0634\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 1s 763us/step - loss: 177.0698 - mse: 177.0698\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 1s 819us/step - loss: 177.4398 - mse: 177.4398\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 1s 755us/step - loss: 173.9111 - mse: 173.9110\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 1s 791us/step - loss: 176.5302 - mse: 176.5302\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 1s 759us/step - loss: 171.3673 - mse: 171.3673\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 1s 749us/step - loss: 176.2465 - mse: 176.2465\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 1s 767us/step - loss: 174.1435 - mse: 174.1435\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 1s 877us/step - loss: 174.3477 - mse: 174.3477\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 1s 899us/step - loss: 172.3974 - mse: 172.3974\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 1s 810us/step - loss: 170.0151 - mse: 170.0151\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 1s 757us/step - loss: 173.7391 - mse: 173.7391\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 1s 759us/step - loss: 170.9233 - mse: 170.9233\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 1s 782us/step - loss: 173.2392 - mse: 173.2392\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 1s 949us/step - loss: 172.2860 - mse: 172.2860\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 1s 784us/step - loss: 173.4647 - mse: 173.4647\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 1s 793us/step - loss: 167.5969 - mse: 167.5969\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 1s 882us/step - loss: 169.4271 - mse: 169.4271\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 1s 811us/step - loss: 170.1186 - mse: 170.1186\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 1s 915us/step - loss: 170.7007 - mse: 170.7007\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 1s 964us/step - loss: 169.3393 - mse: 169.3393\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 1s 790us/step - loss: 168.6548 - mse: 168.6548\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 1s 775us/step - loss: 167.9398 - mse: 167.9398\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 169.6279 - mse: 169.6279\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 1s 899us/step - loss: 167.4892 - mse: 167.4892\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 1s 858us/step - loss: 167.4079 - mse: 167.4079\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 1s 858us/step - loss: 168.5141 - mse: 168.5141\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 1s 903us/step - loss: 167.6894 - mse: 167.6894\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 169.6930 - mse: 169.6930\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 1s 858us/step - loss: 167.3047 - mse: 167.3047\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 1s 850us/step - loss: 170.2496 - mse: 170.2496\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 1s 854us/step - loss: 166.7420 - mse: 166.7420\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 1s 909us/step - loss: 166.2471 - mse: 166.2471\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 1s 956us/step - loss: 168.1260 - mse: 168.1260\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 1s 839us/step - loss: 165.6072 - mse: 165.6072\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 1s 781us/step - loss: 167.6199 - mse: 167.6199\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 1s 789us/step - loss: 168.7030 - mse: 168.7030\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 1s 878us/step - loss: 163.5951 - mse: 163.5951\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 1s 872us/step - loss: 162.9289 - mse: 162.9289\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 1s 800us/step - loss: 165.7049 - mse: 165.7049\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 1s 806us/step - loss: 165.0278 - mse: 165.0278\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 1s 812us/step - loss: 164.6482 - mse: 164.6482\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 1s 820us/step - loss: 162.7989 - mse: 162.7989\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 1s 816us/step - loss: 164.6683 - mse: 164.6683\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 1s 803us/step - loss: 168.5013 - mse: 168.5013\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 1s 822us/step - loss: 163.6936 - mse: 163.6936\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 1s 847us/step - loss: 163.8749 - mse: 163.8749\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 1s 878us/step - loss: 162.5478 - mse: 162.5478\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 864us/step - loss: 165.7792 - mse: 165.7792\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 1s 822us/step - loss: 165.1205 - mse: 165.1205\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 1s 811us/step - loss: 162.4999 - mse: 162.4999\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 1s 937us/step - loss: 166.3428 - mse: 166.3428\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 1s 969us/step - loss: 164.1360 - mse: 164.1360\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 1s 904us/step - loss: 165.6140 - mse: 165.6140\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 1s 831us/step - loss: 162.8651 - mse: 162.8651\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 1s 789us/step - loss: 166.5254 - mse: 166.5254\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 1s 818us/step - loss: 160.6071 - mse: 160.6071\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 1s 919us/step - loss: 162.6404 - mse: 162.6404\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 1s 796us/step - loss: 166.9867 - mse: 166.9867\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 1s 829us/step - loss: 163.4897 - mse: 163.4897\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 1s 968us/step - loss: 164.8008 - mse: 164.8008\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 162.8811 - mse: 162.8811\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 167.0632 - mse: 167.0632\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 1s 866us/step - loss: 162.2452 - mse: 162.2452\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 1s 919us/step - loss: 165.0383 - mse: 165.0383\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 1s 941us/step - loss: 162.6405 - mse: 162.6405\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 1s 859us/step - loss: 166.5480 - mse: 166.5480\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 1s 781us/step - loss: 161.5634 - mse: 161.5634\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 1s 831us/step - loss: 166.1001 - mse: 166.1001\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 1s 970us/step - loss: 164.1705 - mse: 164.1705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x22e76af4340>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=np.array(xy_set), y=np.array(z_set), batch_size=10, epochs=100, verbose=1, callbacks=None, \n",
    "         validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None,\n",
    "         initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(xy_set[:, 0], xy_set[:, 1], z_set, c='blue', marker='o')\n",
    "result_set = model.predict(xy_set)\n",
    "ax.scatter(xy_set[:, 0], xy_set[:, 1], result_set, c='red', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a214da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
